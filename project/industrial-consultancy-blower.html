<!-- ================= REPRESENTATIVE CODE SAMPLES ================= -->
<section class="section">
  <h2>Representative Code Samples</h2>

  <p>
    Below are representative excerpts from computational workflows I have developed
    using OpenFOAM and Physics-Informed Neural Networks (PINNs). These examples
    demonstrate solver setup, numerical modeling, and data-driven acceleration of
    physics-based simulations.
  </p>

  <!-- ================= OPENFOAM ================= -->
  <h3>OpenFOAM — Bioheat & CFD Solver Configuration</h3>

  <p>
    Example configuration used for transient heat transfer and flow simulations,
    including mesh control, solver selection, and numerical stability settings.
  </p>

  <pre><code>
// system/fvSchemes
ddtSchemes
{
    default         Euler;
}

gradSchemes
{
    default         Gauss linear;
}

divSchemes
{
    div(phi,U)      Gauss upwind;
    div(phi,T)      Gauss linear;
}

laplacianSchemes
{
    default         Gauss linear corrected;
}
  </code></pre>

  <pre><code>
// system/fvSolution
solvers
{
    T
    {
        solver          PCG;
        preconditioner  DIC;
        tolerance       1e-8;
        relTol          0.01;
    }
}

PISO
{
    nCorrectors     2;
    nNonOrthogonalCorrectors 1;
}
  </code></pre>

  <!-- ================= PINN ================= -->
  <h3>Physics-Informed Neural Networks (PINNs) — Thermal Modeling</h3>

  <p>
    Example Python code illustrating a PINN setup for solving a physics-constrained
    heat equation, combining neural networks with governing equations and boundary
    conditions.
  </p>

  <pre><code class="language-python">
import torch
import torch.nn as nn

class PINN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(2, 64),
            nn.Tanh(),
            nn.Linear(64, 64),
            nn.Tanh(),
            nn.Linear(64, 1)
        )

    def forward(self, x):
        return self.net(x)


def heat_equation_loss(model, x, t, alpha):
    x.requires_grad_(True)
    t.requires_grad_(True)

    u = model(torch.cat([x, t], dim=1))
    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]
    u_x = torch.autograd.grad(u, x, torch.ones_like(u), create_graph=True)[0]
    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x), create_graph=True)[0]

    return torch.mean((u_t - alpha * u_xx) ** 2)
  </code></pre>

  <p>
    These models were used to accelerate parametric studies while preserving
    physical consistency, enabling faster engineering decision-making compared
    to full-order numerical simulations.
  </p>
</section>

